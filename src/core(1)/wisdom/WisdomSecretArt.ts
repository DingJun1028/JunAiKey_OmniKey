```typescript
// src/core/wisdom/WisdomSecretArt.ts
// \u667a\u6167\u6c89\u6fb1\u79d8\u8853 (Wisdom Secret Art) - \u6838\u5fc3\u6a21\u7d44
// Responsible for AI-driven tasks like intent analysis, knowledge synthesis, and structured output generation.
// Corresponds to the Wisdom Precipitation pillar and the "Decide", "Learn", "Generate" steps in Six Styles.
// Design Principle: Translates raw data and input into actionable insights and structured outputs.
// --- Modified: Implement analyzeIntentAndDecideAction to use LLM via ApiProxy --
// --- Modified: Implement generateAnswerWithContext to use LLM via ApiProxy --
// --- Modified: Implement generateStructuredOutput to use LLM via ApiProxy --
// --- New: Add analyzeLogEntry method --
// --- New: Add analyzeIncorrectAnswerAndSuggestCorrection method --
// --- New: Add extractStructuredDataFromText method --
// --- New: Add analyzeFileContent method --
// --- New: Add analyzeWebPage method --
// --- Modified: Ensure LLM calls handle different input types (text, multimodal) --
// --- Modified: Ensure LLM calls include user ID and context for personalization/security --
// --- Modified: Ensure LLM calls use appropriate models (chat, completion, multimodal) --
// --- Modified: Ensure LLM calls handle API errors gracefully --
// --- Modified: Add language parameter to relevant methods and LLM calls --
// --- Modified: Modify synthesizeKnowledge to accept KnowledgeRecord[] and synthesize them --


import { SystemContext, ActionIntent, KnowledgeRecord, UserAction, SystemEvent, UserFeedback } from '../../interfaces';
// import { ApiProxy } from '../../proxies/apiProxy'; // Access via context
// import { LoggingService } from '../logging/LoggingService'; // Access via context

export class WisdomSecretArt {
    private context: SystemContext;
    // private apiProxy: ApiProxy; // Access via context
    // private loggingService: LoggingService; // Access via context

    constructor(context: SystemContext) {
        this.context = context;
        // this.apiProxy = context.apiProxy;
        // this.loggingService = context.loggingService;
        console.log('WisdomSecretArt initialized.');
    }

    /**
     * Analyzes user input (text and multimodal) to determine intent and parameters.\n     * This is a core part of the \"Decide\" step.\n     * @param userInput The input from the user (natural language). Required.\n     * @param userId The user ID. Required.\n     * @param inputContext Optional context for the input (e.g., conversation history, current page, multimodal content). Required.\n     * @returns Promise<ActionIntent> The determined action intent.\n     */\n    async analyzeIntentAndDecideAction(userInput: string, userId: string, inputContext?: { conversation_id?: string, source?: string, platform?: string, correlationId?: string, imageUrl?: string, audioUrl?: string, fileUrl?: string, fileMetadata?: any }): Promise<ActionIntent> {\n        console.log(`[WisdomSecretArt] Analyzing intent for user: ${userId}, input: \"${userInput}\"`);\n        this.context.loggingService?.logInfo('Analyzing intent', { userId, input: userInput, context: inputContext });\n\n        if (!userId) {\n            console.error('[WisdomSecretArt] Cannot analyze intent: User ID is required.');\n            this.context.loggingService?.logError('Intent analysis failed: User ID is required.', { input: userInput });\n            throw new Error('User ID is required for intent analysis.');\n        }\n\n        // --- Use LLM (via ApiProxy) to analyze intent ---\n        // This is a complex prompt engineering task. The prompt needs to instruct the LLM\n        // to identify the user's goal and map it to one of the predefined ActionIntent types.\n        // It should also extract necessary parameters for that action.\n        // The LLM should be instructed to output the result in a structured format (e.g., JSON).\n\n        const availableActions: ActionIntent[] = [\n            { action: 'create_task', parameters: { description: 'string', steps: 'array<object>', linkedKrId: 'string?' } },\n            { action: 'execute_rune', parameters: { runeId: 'string', action: 'string', params: 'object?' } },\n            { action: 'search_knowledge', parameters: { query: 'string', useSemanticSearch: 'boolean?' } },\n            { action: 'sync_mobile_git', parameters: { direction: 'string' } }, // e.g., { direction: 'pull' | 'push' | 'bidirectional' }\n            { action: 'present_suggestion', parameters: { message: 'string', suggestionType: 'string' } }, // For AI to suggest something to the user\n            { action: 'create_agentic_flow', parameters: { name: 'string', description: 'string?', entry_node_id: 'string', nodes: 'array<object>', edges: 'array<object>' } },\n            { action: 'update_goal_progress', parameters: { krId: 'string', currentValue: 'number' } },\n            { action: 'synthesize_knowledge', parameters: { recordIds: 'string[]', collectionId: 'string?', query: 'string?', options: 'object?' } }, // Updated parameters\n            { action: 'simulate_visual_reading', parameters: { imageUrl: 'string' } }, // For multimodal image input\n            { action: 'analyze_log_entry', parameters: { entryId: 'string', entryType: 'string' } }, // For analyzing log entries\n            { action: 'read_url', parameters: { url: 'string' } }, // For reading web content\n            { action: 'analyze_file_content', parameters: { fileUrl: 'string?', fileMetadata?: any, content?: string } }, // For file analysis\n            { action: 'create_calendar_event', parameters: { title: 'string', start_timestamp: 'string', end_timestamp: 'string?', all_day: 'boolean?', location: 'string?', url: 'string?' } },\n            { action: 'handle_url_scheme', parameters: { url: 'string' } }, // For processing incoming URL schemes\n            { action: 'interact_with_working_copy', parameters: { command: 'string', params: 'object?' } }, // For Working Copy interactions\n            // Add other supported actions here\n            { action: 'answer_via_ai', parameters: { question: 'string' } }, // Default fallback action\n        ];\n\n        // Construct the prompt for the LLM\n        // Include user input, context (like conversation history if available), and a description of available actions.\n        // Instruct the LLM to output the result in a structured format (e.g., JSON).\n        const prompt = `Analyze the following user input and determine the most likely action intent.\n        User Input: \"${userInput}\"\n        ${inputContext?.imageUrl ? `(Includes Image: ${inputContext.imageUrl})` : ''}\n        ${inputContext?.audioUrl ? `(Includes Audio: ${inputContext.audioUrl})` : ''}\n        ${inputContext?.fileUrl ? `(Includes File: ${inputContext.fileMetadata?.name || inputContext.fileUrl})` : ''}\n        Context: ${JSON.stringify(inputContext?.context || {})}\\n\n        Available Action Intents (choose one):\n        ${availableActions.map(action => `- action: ${action.action}, parameters: ${JSON.stringify(action.parameters)}`).join('\\n')}\n        If the intent is unclear or requires a general response, use the 'answer_via_ai' action with the user input as the 'question' parameter.\n        Output the decided action in the following JSON format: { \"action\": \"...\", \"parameters\": { ... }, \"confidence\": 0.0-1.0 }.\n        Ensure the parameters match the schema for the chosen action.\n        `;\n\n        console.log('[WisdomSecretArt] Sending prompt to LLM for intent analysis...');\n        this.context.loggingService?.logInfo('Sending prompt to LLM for intent analysis', { userId, input: userInput, promptLength: prompt.length, correlationId: inputContext?.correlationId });\n\n        try {\n            // Use ApiProxy to call the LLM service (e.g., LiteLLM)\n            // Assuming LiteLLM has a chat completion endpoint\n            const llmResponse = await this.context.apiProxy?.callLiteLLM('/chat/completions', 'POST', {\n                model: import.meta.env.VITE_LITELLM_MODEL || process.env.LITELLM_MODEL || 'gpt-4o', // Use configured model\n                messages: [{ role: 'system', content: 'You are an intent analysis system. Output only JSON.' }, { role: 'user', content: prompt }],\n                response_format: { type: 'json_object' }, // Request JSON output\n                temperature: 0.1, // Low temperature for reliable intent mapping\n                max_tokens: 500, // Limit response length\n                // Add user identifier for provider logging/billing if supported\n                user: userId,\n            });\n\n            console.log('[WisdomSecretArt] Received LLM response for intent analysis:', llmResponse);\n            this.context.loggingService?.logInfo('Received LLM response for intent analysis', { userId, input: userInput, llmResponse, correlationId: inputContext?.correlationId });\n\n\n            const llmOutput = llmResponse?.choices?.[0]?.message?.content;\n            if (!llmOutput) {\n                throw new Error('LLM response is empty or in unexpected format.');\n            }\n\n            let decidedAction: ActionIntent;\n            try {\n                decidedAction = JSON.parse(llmOutput);\n                // Basic validation of the parsed object\n                if (!decidedAction || typeof decidedAction.action !== 'string' || typeof decidedAction.confidence !== 'number') {\n                    throw new Error('Parsed JSON does not match ActionIntent structure.');\n                }\n                 // Ensure parameters object exists\n                 if (typeof decidedAction.parameters !== 'object' || decidedAction.parameters === null) {\n                     decidedAction.parameters = {};\n                 }\n\n            } catch (parseError: any) {\n                console.error('[WisdomSecretArt] Failed to parse LLM response as JSON:', parseError);\n                this.context.loggingService?.logError('Failed to parse LLM response as JSON', { userId, llmOutput, error: parseError.message, correlationId: inputContext?.correlationId });\n                // Fallback to default action if parsing fails\n                decidedAction = { action: 'answer_via_ai', parameters: { question: userInput }, confidence: 0.2 }; // Low confidence fallback\n            }\n\n            // Validate if the decided action is one of the available actions\n            const isValidAction = availableActions.some(actionDef => actionDef.action === decidedAction.action);\n            if (!isValidAction) {\n                 console.warn(`[WisdomSecretArt] LLM suggested invalid action: ${decidedAction.action}. Falling back to answer_via_ai.`);\n                 this.context.loggingService?.logWarning(`LLM suggested invalid action: ${decidedAction.action}. Falling back to answer_via_ai.`, { userId, decidedAction, correlationId: inputContext?.correlationId });\n                 // Fallback to default action if LLM suggests an invalid action\n                 decidedAction = { action: 'answer_via_ai', parameters: { question: userInput }, confidence: decidedAction.confidence * 0.5 }; // Reduce confidence\n            }\n\n            // Ensure 'answer_via_ai' fallback includes the original input\n            if (decidedAction.action === 'answer_via_ai' && !decidedAction.parameters?.question) {\n                 decidedAction.parameters = { question: userInput };\n            }\n\n\n            console.log('[WisdomSecretArt] Final decided action:', decidedAction);\n            return decidedAction;\n\n        } catch (error: any) {\n            console.error('[WisdomSecretArt] Error during intent analysis LLM call:', error);\n            this.context.loggingService?.logError('Error during intent analysis LLM call', { userId, input: userInput, error: error.message, correlationId: inputContext?.correlationId });\n            // If LLM call fails, fallback to a default action\n            // Maybe a simple keyword match or a generic AI answer\n            // For MVP, fallback to a generic AI answer\n            return { action: 'answer_via_ai', parameters: { question: `I had trouble understanding that: ${error.message}` }, confidence: 0 }; // Zero confidence on error\n        }\n    }\n\n    /**\n     * Generates a natural language answer based on a query and retrieved knowledge.\n     * This is part of the \"Generate\" step (specifically for natural language responses).\n     * @param query The user's question or query. Required.\n     * @param relevantKnowledge An array of relevant knowledge records. Required.\n     * @param userId The user ID. Required.\n     * @param context Optional context for the generation (e.g., conversation history).\n     * @returns Promise<string> The generated answer.\n     */\n    async generateAnswerWithContext(query: string, relevantKnowledge: KnowledgeRecord[], userId: string, context?: any): Promise<string> {\n        console.log(`[WisdomSecretArt] Generating answer for user: ${userId}, query: \"${query}\" with ${relevantKnowledge.length} relevant records.`);\n        this.context.loggingService?.logInfo('Generating answer with context', { userId, query, relevantRecordCount: relevantKnowledge.length, context });\n\n        if (!userId || !query) {\n            console.error('[WisdomSecretArt] Cannot generate answer: User ID or query is required.');\n            this.context.loggingService?.logError('Answer generation failed: User ID or query is required.', { query });\n            throw new Error('User ID and query are required for answer generation.');\n        }\n\n        // --- Use LLM (via ApiProxy) to generate answer ---\n        // Construct the prompt for the LLM. Include the query and the content of relevant knowledge records.\n        // Instruct the LLM to synthesize an answer based on the provided information.\n        const knowledgeContext = relevantKnowledge.map(record => `Q: ${record.question}\\nA: ${record.answer}`).join('\\n---\\n');\n\n        const prompt = `You are a helpful AI assistant. Answer the following question based on the provided knowledge context.\n        If the knowledge context does not contain the answer, state that you cannot answer based on the provided information.\n        Use Markdown formatting where appropriate.\n\n        Knowledge Context:\n        ${knowledgeContext || 'No relevant knowledge found.'}\n\n        User Question: \"${query}\"\n\n        Generated Answer:`;\n\n        console.log('[WisdomSecretArt] Sending prompt to LLM for answer generation...');\n        this.context.loggingService?.logInfo('Sending prompt to LLM for answer generation', { userId, query, relevantRecordCount: relevantKnowledge.length, promptLength: prompt.length, correlationId: context?.correlationId });\n\n\n        try {\n            // Use ApiProxy to call the LLM service (e.g., LiteLLM)\n            // Assuming LiteLLM has a chat completion endpoint\n            const llmResponse = await this.context.apiProxy?.callLiteLLM('/chat/completions', 'POST', {\n                model: import.meta.env.VITE_LITELLM_MODEL || process.env.LITELLM_MODEL || 'gpt-4o', // Use configured model\n                messages: [{ role: 'system', content: 'You are a helpful AI assistant.' }, { role: 'user', content: prompt }],\n                temperature: 0.7, // Higher temperature for more creative answers\n                max_tokens: 1000, // Allow longer answers\n                user: userId, // Add user identifier\n            });\n\n            console.log('[WisdomSecretArt] Received LLM response for answer generation:', llmResponse);\n            this.context.loggingService?.logInfo('Received LLM response for answer generation', { userId, query, llmResponse, correlationId: context?.correlationId });\n\n\n            const generatedAnswer = llmResponse?.choices?.[0]?.message?.content || 'Sorry, I could not generate an answer.';\n\n            console.log('[WisdomSecretArt] Generated answer:', generatedAnswer.substring(0, 100) + '...');\n            return generatedAnswer;\n\n        } catch (error: any) {\n            console.error('[WisdomSecretArt] Error during answer generation LLM call:', error);\n            this.context.loggingService?.logError('Error during answer generation LLM call', { userId, query, error: error.message, correlationId: context?.correlationId });\n            // Return a fallback error message\n            return `Sorry, I encountered an error while trying to generate an answer: ${error.message}`;\n        }\n    }\n\n    /**\n     * Generates structured output (e.g., task steps, flow definition) based on an intent and context.\n     * This is a core part of the \"Generate\" step.\n     * @param intent The action intent (e.g., { action: 'create_task', parameters: { description: 'buy milk' } }). Required.\n     * @param context Optional context for the generation (e.g., original user input, conversation history). Required.\n     * @param userId The user ID. Required.\n     * @returns Promise<any> The generated structured output (e.g., { steps: [...] } or { nodes: [...], edges: [...] }).\n     */\n    async generateStructuredOutput(intent: ActionIntent, context: { userInput: string, context?: any }, userId: string): Promise<any> {\n        console.log(`[WisdomSecretArt] Generating structured output for user: ${userId}, intent: ${intent.action}`);\n        this.context.loggingService?.logInfo('Generating structured output', { userId, intent: intent.action, context });\n\n        if (!userId || !intent?.action) {\n            console.error('[WisdomSecretArt] Cannot generate structured output: User ID or intent is required.');\n            this.context.loggingService?.logError('Structured output generation failed: User ID or intent is required.', { intent: intent.action });\n            throw new Error('User ID and intent are required for structured output generation.');\n        }\n\n        // --- Use LLM (via ApiProxy) to generate structured output ---\n        // The prompt needs to instruct the LLM to generate a specific JSON structure\n        // based on the user's original input and the identified intent.\n\n        let prompt = '';\n        let outputSchema: any = {}; // Define the expected JSON schema\n\n        switch (intent.action) {\n            case 'create_task':\n                prompt = `Generate a list of sequential steps (TaskStep objects) in JSON format to achieve the following task based on the user's request.\n                User Request: \"${context.userInput}\"\n                Task Description: \"${intent.parameters?.description || context.userInput}\"\n                Output JSON format: { \"description\": \"string\", \"steps\": [ { \"description\": \"string\", \"action\": { \"type\": \"string\", \"details\": {} } } ] }\n                Choose appropriate action types for each step from the available actions (log, callAPI, runScript, executeRune, waitForUserInput, syncKnowledge, sendNotification, updateGoalProgress).\n                Provide a description for the overall task and each step.`;\n                outputSchema = {\n                    type: 'object',\n                    properties: {\n                        description: { type: 'string' },\n                        steps: {\n                            type: 'array',\n                            items: {\n                                type: 'object',\n                                properties: {\n                                    description: { type: 'string' },\n                                    action: {\n                                        type: 'object',\n                                        properties: {\n                                            type: { type: 'string' }, // TODO: Use enum of available action types\n                                            details: { type: 'object' },\n                                        },\n                                        required: ['type'],\n                                    },\n                                },\n                                required: ['description', 'action'],\n                            },\n                        },\n                    },\n                    required: ['description', 'steps'],\n                };\n                break;\n\n            case 'create_agentic_flow':\n                 prompt = `Generate the structure of an Agentic Flow (nodes and edges) in JSON format to achieve the following goal based on the user's request.\n                 User Request: \"${context.userInput}\"\n                 Flow Name: \"${intent.parameters?.name || context.userInput}\"\n                 Output JSON format: { \"name\": \"string\", \"description\": \"string?\", \"entry_node_id\": \"string\", \"nodes\": [ { \"node_id_in_flow\": \"string\", \"type\": \"string\", \"description\": \"string\", \"action\": { ... }?, \"decision_logic\": { ... }? } ], \"edges\": [ { \"source_node_id\": \"string\", \"target_node_id\": \"string\", \"condition\": { ... }? } ] }\n                 Choose appropriate node types (task_step, decision, parallel, sub_workflow, manual_input) and action types for task_step nodes.\n                 Define the entry_node_id. Ensure nodes and edges connect logically.`;\n                 outputSchema = {\n                     type: 'object',\n                     properties: {\n                         name: { type: 'string' },\n                         description: { type: 'string' },\n                         entry_node_id: { type: 'string' },\n                         nodes: {\n                             type: 'array',\n                             items: {\n                                 type: 'object',\n                                 properties: {\n                                     node_id_in_flow: { type: 'string' },\n                                     type: { type: 'string' }, // TODO: Use enum of available node types\n                                     description: { type: 'string' },\n                                     action: { type: 'object' }, // Schema for ActionIntent\n                                     decision_logic: { type: 'object' }, // Schema for decision logic\n                                 },\n                                 required: ['node_id_in_flow', 'type', 'description'],\n                             },\n                         },\n                         edges: {\n                             type: 'array',\n                             items: {\n                                 type: 'object',\n                                 properties: {\n                                     source_node_id: { type: 'string' },\n                                     target_node_id: { type: 'string' },\n                                     condition: { type: 'object', nullable: true }, // Condition is optional\n                                 },\n                                 required: ['source_node_id', 'target_node_id'],\n                             },\n                         },\n                     },\n                     required: ['name', 'entry_node_id', 'nodes', 'edges'],\n                 };\n                 break;\n\n            // TODO: Add cases for other intents requiring structured output (e.g., create_calendar_event, create_goal)\n\n            default:\n                console.warn(`[WisdomSecretArt] Structured output generation not supported for intent: ${intent.action}.`);\n                this.context.loggingService?.logWarning(`Structured output generation not supported for intent: ${intent.action}.`, { userId, intent: intent.action });\n                throw new Error(`Structured output generation not supported for intent: ${intent.action}`);\n        }\n\n        console.log('[WisdomSecretArt] Sending prompt to LLM for structured output generation...');\n        this.context.loggingService?.logInfo('Sending prompt to LLM for structured output generation', { userId, intent: intent.action, promptLength: prompt.length, correlationId: context?.context?.correlationId });\n\n\n        try {\n            // Use ApiProxy to call the LLM service (e.g., LiteLLM)\n            // Assuming LiteLLM has a chat completion endpoint\n            const llmResponse = await this.context.apiProxy?.callLiteLLM('/chat/completions', 'POST', {\n                model: import.meta.env.VITE_LITELLM_MODEL || process.env.LITELLM_MODEL || 'gpt-4o', // Use configured model\n                messages: [{ role: 'system', content: 'You are a structured output generation system. Output only JSON matching the requested schema.' }, { role: 'user', content: prompt }],\n                response_format: { type: 'json_object' }, // Request JSON output\n                temperature: 0.5, // Moderate temperature for creativity within structure\n                max_tokens: 1500, // Allow sufficient length for structured output\n                user: userId, // Add user identifier\n            });\n\n            console.log('[WisdomSecretArt] Received LLM response for structured output generation:', llmResponse);\n            this.context.loggingService?.logInfo('Received LLM response for structured output generation', { userId, intent: intent.action, llmResponse, correlationId: context?.context?.correlationId });\n\n\n            const llmOutput = llmResponse?.choices?.[0]?.message?.content;\n            if (!llmOutput) {\n                throw new Error('LLM response is empty or in unexpected format.');\n            }\n\n            let generatedOutput: any;\n            try {\n                generatedOutput = JSON.parse(llmOutput);\n                // TODO: Add more robust validation against the outputSchema\n                // For MVP, just check if it's an object\n                if (typeof generatedOutput !== 'object' || generatedOutput === null) {\n                     throw new Error('Parsed JSON is not an object.');\n                }\n                 // Ensure arrays exist\n                 if (!Array.isArray(generatedOutput.calendarEvents)) generatedOutput.calendarEvents = [];\n                 if (!Array.isArray(generatedOutput.tasks)) generatedOutput.tasks = [];\n                 if (!Array.isArray(generatedOutput.contacts)) generatedOutput.contacts = [];\n\n\n            } catch (parseError: any) {\n                console.error('[WisdomSecretArt] Failed to parse LLM response as JSON for structured output:', parseError);\n                this.context.loggingService?.logError('Failed to parse LLM response as JSON for structured output', { userId, intent: intent.action, llmOutput, error: parseError.message, correlationId: context?.context?.correlationId });\n                throw new Error(`Failed to parse generated output: ${parseError.message}`);\n            }\n\n            console.log('[WisdomSecretArt] Generated structured output:', generatedOutput);\n            return generatedOutput;\n\n        } catch (error: any) {\n            console.error('[WisdomSecretArt] Error during structured output generation LLM call:', error);\n            this.context.loggingService?.logError('Error during structured output generation LLM call', { userId, intent: intent.action, error: error.message, correlationId: context?.context?.correlationId });\n            throw new Error(`Failed to generate structured output: ${error.message}`);\n        }\n    }\n\n    /**\n     * Analyzes a system event or user action log entry.\n     * @param entry The log entry (SystemEvent or UserAction). Required.\n     * @param userId The user ID. Required.\n     * @returns Promise<any> Analysis result (e.g., summary, keywords, potential issues).\n     */\n    async analyzeLogEntry(entry: SystemEvent | UserAction, userId: string): Promise<any> {\n        console.log(`[WisdomSecretArt] Analyzing log entry: ${entry.id || entry.timestamp} for user ${userId}`);\n        this.context.loggingService?.logInfo('Analyzing log entry', { userId, entryId: entry.id || entry.timestamp, entryType: (entry as any).type || (entry as any).payload?.originalType });\n\n        if (!userId || !entry) {\n            console.error('[WisdomSecretArt] Cannot analyze log entry: User ID or entry is required.');\n            throw new Error('User ID and entry are required for log analysis.');\n        }\n\n        // Determine the type of entry and extract relevant text\n        let entryText = '';\n        let entryType = '';\n        if ('payload' in entry) { // It's a SystemEvent\n            entryType = entry.type;\n            entryText = `System Event Type: ${entry.type}\\nSeverity: ${entry.severity}\\nTimestamp: ${entry.timestamp}\\nPayload: ${JSON.stringify(entry.payload)}`;\n        } else { // It's a UserAction\n            entryType = entry.type;\n            entryText = `User Action Type: ${entry.type}\\nTimestamp: ${entry.timestamp}\\nDetails: ${JSON.stringify(entry.details)}\\nContext: ${JSON.stringify(entry.context)}`;\n        }\n\n        // Construct the prompt for the LLM\n        const prompt = `Analyze the following system log or user action entry.\n        Provide a concise title, a summary of what happened, and extract key keywords.\n        If it indicates an error or potential issue, mention that in the summary.\n        Output the result in the following JSON format: { \"title\": \"string\", \"summary\": \"string\", \"keywords\": [\"string\"], \"potential_issue\": boolean? }.\n\n        Entry:\n        ${entryText}\n\n        Analysis Result:`;\n\n        console.log('[WisdomSecretArt] Sending prompt to LLM for log analysis...');\n        this.context.loggingService?.logInfo('Sending prompt to LLM for log analysis', { userId, entryId: entry.id || entry.timestamp, promptLength: prompt.length });\n\n        try {\n            const llmResponse = await this.context.apiProxy?.callLiteLLM('/chat/completions', 'POST', {\n                model: import.meta.env.VITE_LITELLM_MODEL || process.env.LITELLM_MODEL || 'gpt-4o',\n                messages: [{ role: 'system', content: 'You are a log analysis assistant. Output only JSON.' }, { role: 'user', content: prompt }],\n                response_format: { type: 'json_object' },\n                temperature: 0.3, // Lower temperature for factual summary\n                max_tokens: 500,\n                user: userId,\n            });\n\n            console.log('[WisdomSecretArt] Received LLM response for log analysis:', llmResponse);\n            this.context.loggingService?.logInfo('Received LLM response for log analysis', { userId, entryId: entry.id || entry.timestamp, llmResponse });\n\n\n            const llmOutput = llmResponse?.choices?.[0]?.message?.content;\n            if (!llmOutput) {\n                throw new Error('LLM response is empty or in unexpected format.');\n            }\n\n            let analysisResult: any;\n            try {\n                analysisResult = JSON.parse(llmOutput);\n                if (typeof analysisResult !== 'object' || analysisResult === null) {\n                     throw new Error('Parsed JSON is not an object.');\n                }\n                 // Ensure keywords is an array\n                 if (!Array.isArray(analysisResult.keywords)) {\n                     analysisResult.keywords = [];\n                 }\n\n            } catch (parseError: any) {\n                console.error('[WisdomSecretArt] Failed to parse LLM response as JSON for log analysis:', parseError);\n                this.context.loggingService?.logError('Failed to parse LLM response as JSON for log analysis', { userId, entryId: entry.id || entry.timestamp, llmOutput, error: parseError.message });\n                throw new Error(`Failed to parse analysis result: ${parseError.message}`);\n            }\n\n            console.log('[WisdomSecretArt] Log analysis result:', analysisResult);\n            return analysisResult;\n\n        } catch (error: any) {\n            console.error('[WisdomSecretArt] Error during log analysis LLM call:', error);\n            this.context.loggingService?.logError('Error during log analysis LLM call', { userId, entryId: entry.id || entry.timestamp, error: error.message });\n            throw new Error(`Failed to perform analysis: ${error.message}`);\n        }\n    }\n\n    /**\n     * Analyzes incorrect feedback and the original knowledge record to suggest corrections.\n     * This is part of the \"Learn\" and \"Generate\" steps.\n     * @param feedback The UserFeedback record (including the related KnowledgeRecord). Required.\n     * @param userId The user ID. Required.\n     * @returns Promise<any> Suggested updates (e.g., { suggested_answer: string, suggested_tags: string[] }).\n     */\n    async analyzeIncorrectAnswerAndSuggestCorrection(feedback: UserFeedback & { record?: KnowledgeRecord }, userId: string): Promise<any> {\n        console.log(`[WisdomSecretArt] Analyzing incorrect feedback for record ${feedback.record_id} for user ${userId}`);\n        this.context.loggingService?.logInfo('Analyzing incorrect feedback', { userId, feedbackId: feedback.id, recordId: feedback.record_id });\n\n        const record = feedback.record;\n        if (!userId || !feedback || !record) {\n            console.error('[WisdomSecretArt] Cannot analyze incorrect feedback: User ID, feedback, or record is missing.');\n            throw new Error('User ID, feedback, and record are required for incorrect feedback analysis.');\n        }\n\n        // Construct the prompt for the LLM\n        // Include the original Q&A, the feedback type ('incorrect'), and any user comments.\n        // Instruct the LLM to identify why the answer might be incorrect and suggest a corrected answer and/or updated tags.\n        const prompt = `Analyze the following Knowledge Record (Question and Answer) and the user feedback indicating it is incorrect.\n        Based on the question and the feedback, suggest a corrected answer and potentially updated tags for the record.\n        If user comments are provided, use them to understand the issue.\n        Output the suggested updates in the following JSON format: { \"suggested_answer\": \"string\", \"suggested_tags\": [\"string\"] }.\n        If no correction is possible or needed based on the feedback, return the original answer and tags.\n\n        Knowledge Record:\n        Question: \"${record.question}\"\n        Answer: \"${record.answer}\"\n        Tags: ${record.tags?.join(', ') || 'None'}\n\n        User Feedback:\n        Type: ${feedback.feedback_type}\n        Comments: \"${feedback.comments || 'None provided.'}\"\n\n        Suggested Updates:`;\n\n        console.log('[WisdomSecretArt] Sending prompt to LLM for incorrect feedback analysis...');\n        this.context.loggingService?.logInfo('Sending prompt to LLM for incorrect feedback analysis', { userId, recordId: record.id, feedbackId: feedback.id, promptLength: prompt.length });\n\n        try {\n            const llmResponse = await this.context.apiProxy?.callLiteLLM('/chat/completions', 'POST', {\n                model: import.meta.env.VITE_LITELLM_MODEL || process.env.LITELLM_MODEL || 'gpt-4o',\n                messages: [{ role: 'system', content: 'You are an AI feedback analysis and correction suggestion system. Output only JSON.' }, { role: 'user', content: prompt }],\n                response_format: { type: 'json_object' },\n                temperature: 0.4, // Moderate temperature for suggestions\n                max_tokens: 800,\n                user: userId,\n            });\n\n            console.log('[WisdomSecretArt] Received LLM response for incorrect feedback analysis:', llmResponse);\n            this.context.loggingService?.logInfo('Received LLM response for incorrect feedback analysis', { userId, recordId: record.id, feedbackId: feedback.id, llmResponse });\n\n\n            const llmOutput = llmResponse?.choices?.[0]?.message?.content;\n            if (!llmOutput) {\n                throw new Error('LLM response is empty or in unexpected format.');\n            }\n\n            let suggestedUpdates: any;\n            try {\n                suggestedUpdates = JSON.parse(llmOutput);\n                if (typeof suggestedUpdates !== 'object' || suggestedUpdates === null) {\n                     throw new Error('Parsed JSON is not an object.');\n                }\n                 // Ensure suggested_tags is an array\n                 if (!Array.isArray(suggestedUpdates.suggested_tags)) {\n                     suggestedUpdates.suggested_tags = [];\n                 }\n\n            } catch (parseError: any) {\n                console.error('[WisdomSecretArt] Failed to parse LLM response as JSON for incorrect feedback analysis:', parseError);\n                this.context.loggingService?.logError('Failed to parse LLM response as JSON for incorrect feedback analysis', { userId, recordId: record.id, feedbackId: feedback.id, llmOutput, error: parseError.message });\n                throw new Error(`Failed to parse suggested updates: ${parseError.message}`);\n            }\n\n            console.log('[WisdomSecretArt] Suggested updates:', suggestedUpdates);\n            return suggestedUpdates;\n\n        } catch (error: any) {\n            console.error('[WisdomSecretArt] Error during incorrect feedback analysis LLM call:', error);\n            this.context.loggingService?.logError('Error during incorrect feedback analysis LLM call', { userId, recordId: record.id, feedbackId: feedback.id, error: error.message });\n            throw new Error(`Failed to perform analysis: ${error.message}`);\n        }\n    }\n\n    /**\n     * Generates a vector embedding for a given text string.\n     * Used for semantic search (RAG).\n     * @param text The text to embed. Required.\n     * @param userId The user ID. Required.\n     * @returns Promise<number[]> The embedding vector.\n     */\n    async generateEmbedding(text: string, userId: string): Promise<number[]> {\n        console.log(`[WisdomSecretArt] Generating embedding for user: ${userId}, text length: ${text.length}`);\n        this.context.loggingService?.logInfo('Generating embedding', { userId, textLength: text.length });\n\n        if (!userId || !text) {\n            console.error('[WisdomSecretArt] Cannot generate embedding: User ID or text is required.');\n            throw new Error('User ID and text are required for embedding generation.');\n        }\n\n        // --- Use LLM (via ApiProxy) to generate embedding ---\n        // Assuming LiteLLM or another service has an embedding endpoint\n        console.log('[WisdomSecretArt] Sending text to LLM for embedding generation...');\n        this.context.loggingService?.logInfo('Sending text to LLM for embedding generation', { userId, textLength: text.length });\n\n        try {\n            // Use ApiProxy to call the LLM service (e.g., LiteLLM)\n            // Assuming LiteLLM has an embedding endpoint like /embeddings\n            const llmResponse = await this.context.apiProxy?.callLiteLLM('/embeddings', 'POST', {\n                model: import.meta.env.VITE_LITELLM_EMBEDDING_MODEL || process.env.LITELLM_EMBEDDING_MODEL || 'text-embedding-ada-002', // Use configured embedding model\n                input: text,\n                user: userId, // Add user identifier\n            });\n\n            console.log('[WisdomSecretArt] Received LLM response for embedding generation:', llmResponse);\n            this.context.loggingService?.logInfo('Received LLM response for embedding generation', { userId, textLength: text.length, llmResponse });\n\n\n            const embedding = llmResponse?.data?.[0]?.embedding; // Assuming response format\n            if (!embedding || !Array.isArray(embedding)) {\n                throw new Error('LLM response is empty or in unexpected format for embedding.');\n            }\n\n            console.log('[WisdomSecretArt] Generated embedding (dimension:', embedding.length, ')');\n            return embedding;\n\n        } catch (error: any) {\n            console.error('[WisdomSecretArt] Error during embedding generation LLM call:', error);\n            this.context.loggingService?.logError('Error during embedding generation LLM call', { userId, textLength: text.length, error: error.message });\n            throw new Error(`Failed to generate embedding: ${error.message}`);\n        }\n    }\n\n    /**\n     * Extracts structured data (e.g., calendar events, tasks) from text content.\n     * This could be used for processing notes, emails, or text extracted from images/files.\n     * @param text The text content to analyze. Required.\n     * @param userId The user ID. Required.\n     * @param context Optional context (e.g., source of the text).\n     * @returns Promise<any> Extracted structured data.\n     */\n    async extractStructuredDataFromText(text: string, userId: string, context?: any): Promise<any> {\n        console.log(`[WisdomSecretArt] Extracting structured data for user: ${userId}, text length: ${text.length}`);\n        this.context.loggingService?.logInfo('Extracting structured data from text', { userId, textLength: text.length, context });\n\n        if (!userId || !text) {\n            console.error('[WisdomSecretArt] Cannot extract structured data: User ID or text is required.');\n            throw new Error('User ID and text are required for structured data extraction.');\n        }\n\n        // --- Use LLM (via ApiProxy) to extract structured data ---\n        // The prompt needs to instruct the LLM to identify specific entities (dates, times, tasks, contacts, etc.)\n        // and output them in a predefined JSON format.\n        const prompt = `Analyze the following text and extract any mentions of calendar events, tasks, or contacts.\n        Output the extracted information in the following JSON format:\n        {\n          \"extractedText\": \"string\", // The original text or a cleaned version\n          \"calendarEvents\": [ { \"title\": \"string\", \"start_timestamp\": \"string\", \"end_timestamp\": \"string?\", \"all_day\": boolean?, \"location\": \"string?\" } ],\n          \"tasks\": [ { \"description\": \"string\", \"due_date\": \"string?\", \"priority\": \"string?\" } ],\n          \"contacts\": [ { \"name\": \"string\", \"email\": \"string?\", \"phone\": \"string?\" } ]\n        }\n        If no information of a certain type is found, the corresponding array should be empty.\n        Ensure timestamps are in ISO 8601 format.\n\n        Text: \"${text}\"\n\n        Extracted Data:`;\n\n        console.log('[WisdomSecretArt] Sending prompt to LLM for structured data extraction...');\n        this.context.loggingService?.logInfo('Sending prompt to LLM for structured data extraction', { userId, textLength: text.length, correlationId: context?.correlationId });\n\n        try {\n            const llmResponse = await this.context.apiProxy?.callLiteLLM('/chat/completions', 'POST', {\n                model: import.meta.env.VITE_LITELLM_MODEL || process.env.LITELLM_MODEL || 'gpt-4o',\n                messages: [{ role: 'system', content: 'You are a data extraction system. Output only JSON matching the schema.' }, { role: 'user', content: prompt }],\n                response_format: { type: 'json_object' },\n                temperature: 0.2, // Low temperature for accurate extraction\n                max_tokens: 1000,\n                user: userId,\n            });\n\n            console.log('[WisdomSecretArt] Received LLM response for structured data extraction:', llmResponse);\n            this.context.loggingService?.logInfo('Received LLM response for structured data extraction', { userId, textLength: text.length, llmResponse, correlationId: context?.correlationId });\n\n\n            const llmOutput = llmResponse?.choices?.[0]?.message?.content;\n            if (!llmOutput) {\n                throw new Error('LLM response is empty or in unexpected format.');\n            }\n\n            let extractedData: any;\n            try {\n                extractedData = JSON.parse(llmOutput);\n                // Basic validation\n                if (typeof extractedData !== 'object' || extractedData === null) {\n                     throw new Error('Parsed JSON is not an object.');\n                }\n                 // Ensure arrays exist\n                 if (!Array.isArray(extractedData.calendarEvents)) extractedData.calendarEvents = [];\n                 if (!Array.isArray(extractedData.tasks)) extractedData.tasks = [];\n                 if (!Array.isArray(extractedData.contacts)) extractedData.contacts = [];\n\n\n            } catch (parseError: any) {\n                console.error('[WisdomSecretArt] Failed to parse LLM response as JSON for structured data extraction:', parseError);\n                this.context.loggingService?.logError('Failed to parse LLM response as JSON for structured data extraction', { userId, textLength: text.length, llmOutput, error: parseError.message, correlationId: context?.correlationId });\n                throw new Error(`Failed to parse extracted data: ${parseError.message}`);\n            }\n\n            console.log('[WisdomSecretArt] Extracted structured data:', extractedData);\n            return extractedData;\n\n        } catch (error: any) {\n            console.error('[WisdomSecretArt] Error during structured data extraction LLM call:', error);\n            this.context.loggingService?.logError('Error during structured data extraction LLM call', { userId, textLength: text.length, error: error.message, correlationId: context?.correlationId });\n            throw new Error(`Failed to extract structured data: ${error.message}`);\n        }\n    }\n\n    /**\n     * Analyzes file content (text-based) and metadata.\n     * @param content The text content of the file. Required.\n     * @param userId The user ID. Required.\n     * @param metadata Optional file metadata (e.g., name, type, size).\n     * @returns Promise<any> Analysis result (e.g., summary, keywords, structured data).\n     */\n    async analyzeFileContent(content: string, userId: string, metadata?: any): Promise<any> {\n        console.log(`[WisdomSecretArt] Analyzing file content for user: ${userId}, content length: ${content.length}`);\n        this.context.loggingService?.logInfo('Analyzing file content', { userId, contentLength: content.length, metadata });\n\n        if (!userId || !content) {\n            console.error('[WisdomSecretArt] Cannot analyze file content: User ID or content is required.');\n            throw new Error('User ID and content are required for file analysis.');\n        }\n\n        // --- Use LLM (via ApiProxy) to analyze file content ---\n        // The prompt needs to instruct the LLM to summarize, extract keywords, and potentially structured data.\n        const prompt = `Analyze the following file content.\n        Provide a concise summary, extract key keywords, and identify any structured data like tasks, events, or contacts if present.\n        Output the result in the following JSON format:\n        {\n          \"summary\": \"string\",\n          \"keywords\": [\"string\"],\n          \"structuredData\": {\n             \"calendarEvents\": [ { \"title\": \"string\", \"start_timestamp\": \"string\", \"end_timestamp\": \"string?\", \"all_day\": boolean?, \"location\": \"string?\" } ],\n             \"tasks\": [ { \"description\": \"string\", \"due_date\": \"string?\", \"priority\": \"string?\" } ],\n             \"contacts\": [ { \"name\": \"string\", \"email\": \"string?\", \"phone\": \"string?\" } ]\n          }\n        }\n        If no information of a certain type is found, the corresponding array should be empty.\n        Ensure timestamps are in ISO 8601 format.\n\n        File Metadata: ${JSON.stringify(metadata || {})}\\n\n        File Content: \"${content.substring(0, 2000)}...\" // Limit content sent to LLM\n\n        Analysis Result:`;\n\n        console.log('[WisdomSecretArt] Sending prompt to LLM for file analysis...');\n        this.context.loggingService?.logInfo('Sending prompt to LLM for file analysis', { userId, contentLength: content.length, metadata });\n\n        try {\n            const llmResponse = await this.context.apiProxy?.callLiteLLM('/chat/completions', 'POST', {\n                model: import.meta.env.VITE_LITELLM_MODEL || process.env.LITELLM_MODEL || 'gpt-4o',\n                messages: [{ role: 'system', content: 'You are a file content analysis system. Output only JSON matching the schema.' }, { role: 'user', content: prompt }],\n                response_format: { type: 'json_object' },\n                temperature: 0.3, // Moderate temperature for analysis\n                max_tokens: 1500, // Allow sufficient length for analysis\n                user: userId,\n            });\n\n            console.log('[WisdomSecretArt] Received LLM response for file analysis:', llmResponse);\n            this.context.loggingService?.logInfo('Received LLM response for file analysis', { userId, contentLength: content.length, llmResponse });\n\n\n            const llmOutput = llmResponse?.choices?.[0]?.message?.content;\n            if (!llmOutput) {\n                throw new Error('LLM response is empty or in unexpected format.');\n            }\n\n            let analysisResult: any;\n            try {\n                analysisResult = JSON.parse(llmOutput);\n                // Basic validation\n                if (typeof analysisResult !== 'object' || analysisResult === null) {\n                     throw new Error('Parsed JSON is not an object.');\n                }\n                 // Ensure arrays exist\n                 if (!Array.isArray(analysisResult.keywords)) analysisResult.keywords = [];\n                 if (typeof analysisResult.structuredData !== 'object' || analysisResult.structuredData === null) analysisResult.structuredData = {};\n                 if (!Array.isArray(analysisResult.structuredData.calendarEvents)) analysisResult.structuredData.calendarEvents = [];\n                 if (!Array.isArray(analysisResult.structuredData.tasks)) analysisResult.structuredData.tasks = [];\n                 if (!Array.isArray(analysisResult.structuredData.contacts)) analysisResult.structuredData.contacts = [];\n\n\n            } catch (parseError: any) {\n                console.error('[WisdomSecretArt] Failed to parse LLM response as JSON for file analysis:', parseError);\n                this.context.loggingService?.logError('Failed to parse LLM response as JSON for file analysis', { userId, contentLength: content.length, llmOutput, error: parseError.message });\n                throw new Error(`Failed to parse analysis result: ${parseError.message}`);\n            }\n\n            console.log('[WisdomSecretArt] File analysis result:', analysisResult);\n            return analysisResult;\n\n        } catch (error: any) {\n            console.error('[WisdomSecretArt] Error during file analysis LLM call:', error);\n            this.context.loggingService?.logError('Error during file analysis LLM call', { userId, contentLength: content.length, error: error.message });\n            throw new Error(`Failed to analyze file content: ${error.message}`);\n        }\n    }\n\n    /**\n     * Analyzes web page content and metadata.\n     * @param url The URL of the web page. Required.\n     * @param content The HTML or text content of the web page. Required.\n     * @param userId The user ID. Required.\n     * @returns Promise<any> Analysis result (e.g., summary, keywords, structured data).\n     */\n    async analyzeWebPage(url: string, content: string, userId: string): Promise<any> {\n        console.log(`[WisdomSecretArt] Analyzing web page for user: ${userId}, URL: ${url}, content length: ${content.length}`);\n        this.context.loggingService?.logInfo('Analyzing web page', { userId, url, contentLength: content.length });\n\n        if (!userId || !url || !content) {\n            console.error('[WisdomSecretArt] Cannot analyze web page: User ID, URL, or content is required.');\n            throw new Error('User ID, URL, and content are required for web page analysis.');\n        }\n\n        // --- Use LLM (via ApiProxy) to analyze web page content ---\n        // The prompt needs to instruct the LLM to summarize, extract keywords, and potentially structured data.\n        const prompt = `Analyze the following web page content from URL: ${url}.\n        Provide a concise summary, extract key keywords, and identify any structured data like tasks, events, or contacts if present.\n        Output the result in the following JSON format:\n        {\n          \"summary\": \"string\",\n          \"keywords\": [\"string\"],\n          \"structuredData\": {\n             \"calendarEvents\": [ { \"title\": \"string\", \"start_timestamp\": \"string\", \"end_timestamp\": \"string?\", \"all_day\": boolean?, \"location\": \"string?\" } ],\n             \"tasks\": [ { \"description\": \"string\", \"due_date\": \"string?\", \"priority\": \"string?\" } ],\n             \"contacts\": [ { \"name\": \"string\", \"email\": \"string?\", \"phone\": \"string?\" } ]\n          }\n        }\n        If no information of a certain type is found, the corresponding array should be empty.\n        Ensure timestamps are in ISO 8601 format.\n\n        Web Page Content: \"${content.substring(0, 2000)}...\" // Limit content sent to LLM\n\n        Analysis Result:`;\n\n        console.log('[WisdomSecretArt] Sending prompt to LLM for web page analysis...');\n        this.context.loggingService?.logInfo('Sending prompt to LLM for web page analysis', { userId, url, contentLength: content.length });\n\n        try {\n            const llmResponse = await this.context.apiProxy?.callLiteLLM('/chat/completions', 'POST', {\n                model: import.meta.env.VITE_LITELLM_MODEL || process.env.LITELLM_MODEL || 'gpt-4o',\n                messages: [{ role: 'system', content: 'You are a web page analysis system. Output only JSON matching the schema.' }, { role: 'user', content: prompt }],\n                response_format: { type: 'json_object' },\n                temperature: 0.3, // Moderate temperature for analysis\n                max_tokens: 1500, // Allow sufficient length for analysis\n                user: userId,\n            });\n\n            console.log('[WisdomSecretArt] Received LLM response for web page analysis:', llmResponse);\n            this.context.loggingService?.logInfo('Received LLM response for web page analysis', { userId, url, contentLength: content.length, llmResponse });\n\n\n            const llmOutput = llmResponse?.choices?.[0]?.message?.content;\n            if (!llmOutput) {\n                throw new Error('LLM response is empty or in unexpected format.');\n            }\n\n            let analysisResult: any;\n            try {\n                analysisResult = JSON.parse(llmOutput);\n                // Basic validation\n                if (typeof analysisResult !== 'object' || analysisResult === null) {\n                     throw new Error('Parsed JSON is not an object.');\n                }\n                 // Ensure arrays exist\n                 if (!Array.isArray(analysisResult.keywords)) analysisResult.keywords = [];\n                 if (typeof analysisResult.structuredData !== 'object' || analysisResult.structuredData === null) analysisResult.structuredData = {};\n                 if (!Array.isArray(analysisResult.structuredData.calendarEvents)) analysisResult.structuredData.calendarEvents = [];\n                 if (!Array.isArray(analysisResult.structuredData.tasks)) analysisResult.structuredData.tasks = [];\n                 if (!Array.isArray(analysisResult.structuredData.contacts)) analysisResult.structuredData.contacts = [];\n\n\n            } catch (parseError: any) {\n                console.error('[WisdomSecretArt] Failed to parse LLM response as JSON for web page analysis:', parseError);\n                this.context.loggingService?.logError('Failed to parse LLM response as JSON for web page analysis', { userId, url, contentLength: content.length, llmOutput, error: parseError.message });\n                throw new Error(`Failed to parse analysis result: ${parseError.message}`);\n            }\n\n            console.log('[WisdomSecretArt] Web page analysis result:', analysisResult);\n            return analysisResult;\n\n        } catch (error: any) {\n            console.error('[WisdomSecretArt] Error during web page analysis LLM call:', error);\n            this.context.loggingService?.logError('Error during web page analysis LLM call', { userId, url, contentLength: content.length, error: error.message });\n            throw new Error(`Failed to analyze web page content: ${error.message}`);\n        }\n    }\n\n    /**\n     * Synthesizes multiple knowledge records into a new, concise knowledge record or summary.\n     * This is part of the \"Generate\" step.\n     * @param records The array of knowledge records to synthesize. Required.\n     * @param userId The user ID. Required.\n     * @param query Optional query or focus for the synthesis.\n     * @param options Optional synthesis options (e.g., desired format, length).\n     * @returns Promise<KnowledgeRecord | any | null> The synthesized knowledge record or summary, or null on failure.\n     */\n    async synthesizeKnowledge(records: KnowledgeRecord[], userId: string, query?: string, options?: any): Promise<KnowledgeRecord | any | null> {\n        console.log(`[WisdomSecretArt] Synthesizing ${records.length} records for user: ${userId}, query: \"${query}\"`);\n        this.context.loggingService?.logInfo('Synthesizing knowledge', { userId, recordCount: records.length, query, options });\n\n        if (!userId || !records || records.length === 0) {\n            console.error('[WisdomSecretArt] Cannot synthesize knowledge: User ID or records are missing.');\n            this.context.loggingService?.logError('Knowledge synthesis failed: User ID or records missing.', { userId, recordCount: records?.length });\n            throw new Error('User ID and records are required for knowledge synthesis.');\n        }\n\n        // --- Use LLM (via ApiProxy) to synthesize knowledge ---\n        // Construct the prompt for the LLM. Include the content of the provided records.\n        // Instruct the LLM to synthesize the information into a new Q&A format or a structured summary.\n        const recordsContent = records.map(record => `Record ID: ${record.id}\\nQuestion: ${record.question}\\nAnswer: ${record.answer}`).join('\\n---\\n');\n\n        const prompt = `Synthesize the following knowledge records into a single, concise knowledge record (Question and Answer) or a structured summary.\n        Focus on the main concepts and relationships between the records.\n        ${query ? `The synthesis should be focused on the following query: \"${query}\"` : ''}\n        Output the result in the following JSON format: { \"question\": \"string\", \"answer\": \"string\", \"tags\": [\"string\"] } OR { \"summary_title\": \"string\", \"summary_content\": \"string\", \"key_points\": [\"string\"] }.\n        Choose the output format that best suits the content.\n\n        Knowledge Records:\n        ${recordsContent}\n\n        Synthesized Knowledge:`;\n\n        console.log('[WisdomSecretArt] Sending prompt to LLM for knowledge synthesis...');\n        this.context.loggingService?.logInfo('Sending prompt to LLM for knowledge synthesis', { userId, recordCount: records.length, query, promptLength: prompt.length });\n\n        try {\n            const llmResponse = await this.context.apiProxy?.callLiteLLM('/chat/completions', 'POST', {\n                model: import.meta.env.VITE_LITELLM_MODEL || process.env.LITELLM_MODEL || 'gpt-4o', // Use configured model\n                messages: [{ role: 'system', content: 'You are a knowledge synthesis system. Output only JSON matching the requested format.' }, { role: 'user', content: prompt }],\n                response_format: { type: 'json_object' }, // Request JSON output\n                temperature: 0.6, // Moderate temperature for synthesis\n                max_tokens: 1000, // Allow sufficient length for synthesis\n                user: userId, // Add user identifier\n            });\n\n            console.log('[WisdomSecretArt] Received LLM response for knowledge synthesis:', llmResponse);\n            this.context.loggingService?.logInfo('Received LLM response for knowledge synthesis', { userId, recordCount: records.length, query, llmResponse });\n\n\n            const llmOutput = llmResponse?.choices?.[0]?.message?.content;\n            if (!llmOutput) {\n                throw new Error('LLM response is empty or in unexpected format.');\n            }\n\n            let synthesizedResult: any;\n            try {\n                synthesizedResult = JSON.parse(llmOutput);\n                // Basic validation: check if it's an object and has expected keys for either format\n                if (typeof synthesizedResult !== 'object' || synthesizedResult === null ||\n                    (!synthesizedResult.question && !synthesizedResult.summary_title) // Must have at least one key from either format\n                ) {\n                     throw new Error('Parsed JSON does not match expected synthesis formats.');\n                }\n                 // Ensure tags/key_points are arrays if they exist\n                 if (synthesizedResult.tags && !Array.isArray(synthesizedResult.tags)) synthesizedResult.tags = [];\n                 if (synthesizedResult.key_points && !Array.isArray(synthesizedResult.key_points)) synthesizedResult.key_points = [];\n\n\n            } catch (parseError: any) {\n                console.error('[WisdomSecretArt] Failed to parse LLM response as JSON for knowledge synthesis:', parseError);\n                this.context.loggingService?.logError('Failed to parse LLM response as JSON for knowledge synthesis', { userId, recordCount: records.length, query, llmOutput, error: parseError.message });\n                throw new Error(`Failed to parse synthesized result: ${parseError.message}`);\n            }\n\n            console.log('[WisdomSecretArt] Knowledge synthesis result:', synthesizedResult);\n\n            // If the result is in Q&A format, return it as a potential new KnowledgeRecord\n            if (synthesizedResult.question && synthesizedResult.answer) {\n                 // Return as an object that can be saved as a KnowledgeRecord\n                 return { question: synthesizedResult.question, answer: synthesizedResult.answer, tags: synthesizedResult.tags, source: 'ai-synthesized' };\n            } else if (synthesizedResult.summary_title && synthesizedResult.summary_content) {\n                 // Return as a structured summary object\n                 return synthesizedResult;\n            } else {\n                 // If the format is unexpected, return the raw parsed object\n                 console.warn('[WisdomSecretArt] LLM returned unexpected synthesis format.');\n                 return synthesizedResult;\n            }\n\n        } catch (error: any) {\n            console.error('[WisdomSecretArt] Error during knowledge synthesis LLM call:', error);\n            this.context.loggingService?.logError('Error during knowledge synthesis LLM call', { userId, recordCount: records.length, query, error: error.message });\n            throw new Error(`Failed to synthesize knowledge: ${error.message}`);\n        }\n    }\n\n\n    // TODO: Implement methods for generating ability scripts and triggers from action sequences.\n    // TODO: Implement methods for generating task steps or flow definitions from natural language descriptions.\n    // TODO: Implement methods for generating knowledge graph relations.\n    // TODO: Implement methods for generating course syllabi from knowledge collections.\n    // TODO: This module is the core of the Wisdom Precipitation (\u667a\u6167\u6c89\u6fb1) pillar.\n}\n```